from flask import Flask, render_template, request, jsonify, send_from_directory
from flask_cors import CORS
import os
import torch
import timm
import torchvision.transforms as transforms
from PIL import Image
import base64
from io import BytesIO
import json
import shutil
import cv2
import numpy as np
from torch.utils.data import DataLoader
from torchvision import datasets
import time

app = Flask(__name__)
CORS(app)

# üìå ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
UPLOAD_FOLDER = r"C:\‡∏á‡∏≤‡∏ô‡∏ï‡∏±‡πâ‡∏ô\DIP\DIP_project\food_images_1"
STATIC_FOLDER = "static"
TRAINING_FOLDER = "food_images_1"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(TRAINING_FOLDER, exist_ok=True)

# üìå ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üî• ‡πÉ‡∏ä‡πâ: {device}")

# üìå ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
MODEL_PATH = "food_model_vit_best.pth"
CLASS_FILE = "food_classes.json"
NUTRITION_FILE = "food_nutrition.json"

# ‡πÇ‡∏´‡∏•‡∏î CLASS_NAMES ‡∏à‡∏≤‡∏Å food_classes.json
with open("food_classes.json", "r") as f:
    CLASS_NAMES = json.load(f)
    
print(f"üìã CLASS_NAMES: {CLASS_NAMES} (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: {len(CLASS_NAMES)})")

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô food_images_1
print("üìÇ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö food_images_1:")
for folder in os.listdir(TRAINING_FOLDER):
    num_images = len(os.listdir(os.path.join(TRAINING_FOLDER, folder)))
    print(f"  - {folder}: {num_images} ‡∏†‡∏≤‡∏û")

 #‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
if os.path.exists(MODEL_PATH):
    print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ...")
    model = timm.create_model("vit_base_patch16_224", pretrained=False, num_classes=len(CLASS_NAMES))
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model.to(device)
else:
    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà")
    model = timm.create_model("vit_base_patch16_224", pretrained=True, num_classes=len(CLASS_NAMES))
    model.to(device)

model.eval()

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏†‡∏ä‡∏ô‡∏≤‡∏Å‡∏≤‡∏£
try:
    with open(NUTRITION_FILE, "r", encoding="utf-8") as f:
        NUTRITION_DATA = json.load(f)
    print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏†‡∏ä‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {list(NUTRITION_DATA.keys())}")
except FileNotFoundError:
    NUTRITION_DATA = {
        "‡πÅ‡∏Å‡∏á‡∏Ç‡∏µ‡πâ‡πÄ‡∏´‡∏•‡πá‡∏Å": {"calories": 250, "protein": 5, "fat": 8, "carbs": 10},
        "‡∏Ç‡πâ‡∏≤‡∏ß‡∏ú‡∏±‡∏î": {"calories": 200, "protein": 6, "fat": 10, "carbs": 30}
    }
    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö food_nutrition.json ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")

# üìå Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
predict_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# üìå Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

@app.route("/")
def home():
    return render_template("index.html")

@app.route("/food_list", methods=["GET"])
def get_food_list():
    return jsonify(CLASS_NAMES)  # ‡∏™‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ


@app.route('/static/<path:filename>')
def static_files(filename):
    return send_from_directory(STATIC_FOLDER, filename)

def retrain_model(image_path, label):
    global model, CLASS_NAMES

    print(f"üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á Retrain ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏π‡∏õ {image_path} ‡πÄ‡∏õ‡πá‡∏ô {label}")

    # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    
    img = Image.open(image_path).convert("RGB")
    img = transform(img).unsqueeze(0).to(device)

    # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å State ‡πÄ‡∏î‡∏¥‡∏°
    new_model = timm.create_model("vit_base_patch16_224", pretrained=False, num_classes=len(CLASS_NAMES))
    new_model.load_state_dict(model.state_dict(), strict=False)
    new_model.to(device)

    optimizer = torch.optim.AdamW(new_model.parameters(), lr=0.00001)  # üî• ‡∏•‡∏î learning rate
    criterion = torch.nn.CrossEntropyLoss()  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° Loss Function

    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á Label ‡πÄ‡∏õ‡πá‡∏ô Tensor
    label_idx = CLASS_NAMES.index(label)
    label_tensor = torch.tensor([label_idx], dtype=torch.long).to(device)

    # ‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 3-5 Epoch
    epochs = 3
    for epoch in range(epochs):
        optimizer.zero_grad()
        outputs = new_model(img)
        loss = criterion(outputs, label_tensor)
        loss.backward()
        optimizer.step()
        print(f"üü¢ Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}")

    # ‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏Å
    model = new_model
    model.eval()
    torch.save(model.state_dict(), MODEL_PATH)
    print(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà {MODEL_PATH}")

def enhance_image(image):
    img_np = np.array(image)
    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
    img_yuv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YUV)
    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])
    enhanced_img = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)
    enhanced_img = cv2.GaussianBlur(enhanced_img, (5, 5), 0)
    enhanced_img_rgb = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB)
    return Image.fromarray(enhanced_img_rgb)

def detect_edges(image):
    img_np = np.array(image)
    img_gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
    edges = cv2.Canny(img_gray, 100, 200)
    edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
    return Image.fromarray(edges_rgb)

def predict_image(image):
    if NUTRITION_DATA is None:
        return None, 0, {}, ""
    
    enhanced_image = enhance_image(image)
    img = predict_transform(enhanced_image).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(img)
        probs = torch.nn.functional.softmax(output, dim=1)
        conf, predicted_idx = torch.max(probs, 1)

    predicted_class = CLASS_NAMES[predicted_idx.item()]
    confidence = conf.item() * 100
    nutrition = NUTRITION_DATA.get(predicted_class, {})
    
    edge_image = detect_edges(image)
    edge_buffer = BytesIO()
    edge_image.save(edge_buffer, format="JPEG")
    edge_data = base64.b64encode(edge_buffer.getvalue()).decode('utf-8')

    print(f"üîç ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {predicted_class} (Confidence: {confidence:.2f}%)")
    return predicted_class, confidence, nutrition, edge_data

@app.route("/predict", methods=["POST"])
def predict():
    data = request.get_json()
    if not data or 'image' not in data:
        return jsonify({'error': 'No image provided'}), 400
    
    image_data = data['image'].split(',')[1]
    img_bytes = base64.b64decode(image_data)
    img = Image.open(BytesIO(img_bytes)).convert("RGB")
    
    food_name, confidence, nutrition, edge_data = predict_image(img)
    
    if confidence >= 70:
        class_folder = os.path.join(UPLOAD_FOLDER, food_name)
    else:
        class_folder = os.path.join(UPLOAD_FOLDER, "food_data")
    os.makedirs(class_folder, exist_ok=True)
    filename = get_next_filename(f"{food_name}.jpg", class_folder)
    file_path = os.path.join(class_folder, filename)
    img.save(file_path)
    
    response = {
        "food_name": food_name,   # üü¢ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ô‡∏µ‡πâ
        "confidence": f"{confidence:.2f}%",
        "nutrition": nutrition,
        "saved_path": file_path,
        "needs_label": confidence < 70,
        "edge_image": f"data:image/jpeg;base64,{edge_data}"
    }
    print(f"üì§ ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ frontend: {response}")  # üü¢ Debug
    return jsonify(response)

@app.route("/update_label", methods=["POST"])
def update_label():
    global model, CLASS_NAMES

    data = request.get_json()
    print(f"üì• ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤: {data}")  

    if not data or 'path' not in data or 'label' not in data:
        print("‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö")
        return jsonify({'error': '‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö'}), 400

    old_path = data['path']
    new_label = str(data['label']).strip()

    print(f"üìÇ ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö: path={old_path}, label={new_label}")

    if not old_path or not new_label:
        print("‚ùå ‡∏Ñ‡πà‡∏≤ path ‡∏´‡∏£‡∏∑‡∏≠ label ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")
        return jsonify({'error': '‚ùå ‡∏Ñ‡πà‡∏≤ path ‡∏´‡∏£‡∏∑‡∏≠ label ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤'}), 400

    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if not os.path.exists(old_path):
        possible_path = os.path.join(TRAINING_FOLDER, new_label, os.path.basename(old_path))
        if os.path.exists(possible_path):
            print(f"üìÇ ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏¢‡∏±‡∏á: {possible_path}")
            old_path = possible_path
        else:
            print(f"‚ùå ‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏û‡∏ö: {old_path}")
            return jsonify({'error': f"‚ùå ‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏û‡∏ö: {old_path}"}), 400

    # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
    new_folder = os.path.join(TRAINING_FOLDER, new_label)
    os.makedirs(new_folder, exist_ok=True)

    # ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏ò‡πÉ‡∏´‡∏°‡πà‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
    new_path = os.path.join(new_folder, os.path.basename(old_path))

    # ‚úÖ ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà
    shutil.move(old_path, new_path)
    print(f"üìÇ ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å {old_path} ‡πÑ‡∏õ‡∏¢‡∏±‡∏á {new_path}")

    if not os.path.exists(new_path):
        print(f"‚ùå ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {new_path}")
        return jsonify({'error': f"‚ùå ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {new_path}"}), 400

    # ‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï class ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÉ‡∏´‡∏°‡πà
    is_new_class = new_label not in CLASS_NAMES
    if is_new_class:
        CLASS_NAMES.append(new_label)
        with open("food_classes.json", "w") as f:
            json.dump(CLASS_NAMES, f)
        print(f"‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° {new_label} ‡πÉ‡∏ô food_classes.json")

    # ‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
    print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å retrain_model() ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {new_path}")
    retrain_model(new_path, new_label)
    print("‚úÖ Retrain ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

    return jsonify({"status": "success", "message": f"‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡πÄ‡∏õ‡πá‡∏ô {new_label} ‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß"})

def get_next_filename(filename, folder):
    name, ext = os.path.splitext(filename)
    counter = 1
    new_filename = filename
    while os.path.exists(os.path.join(folder, new_filename)):
        new_filename = f"{name}_{counter}{ext}"
        counter += 1
    return new_filename

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)
