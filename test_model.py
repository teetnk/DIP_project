import timm
import torch
import torchvision.transforms as transforms
from PIL import Image
import os

# üìå ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏ò‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•
MODEL_PATH = "food_model_vit.pth"
CLASS_NAMES = ["‡∏Å‡πã‡∏ß‡∏¢‡πÄ‡∏ï‡∏µ‡πã‡∏¢‡∏ß‡πÄ‡∏£‡∏∑‡∏≠", "‡∏Ç‡πâ‡∏≤‡∏ß‡∏Ç‡∏≤‡∏´‡∏°‡∏π", "‡∏Ç‡πâ‡∏≤‡∏ß‡∏°‡∏±‡∏ô‡πÑ‡∏Å‡πà"]  # üîπ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏™‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

# üìå ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Vision Transformer (ViT)
model = timm.create_model("vit_base_patch16_224", pretrained=False, num_classes=len(CLASS_NAMES))
model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device("cpu")))
model.eval()

# üìå ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏†‡∏≤‡∏û
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# üìå ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏†‡∏≤‡∏û
def predict_image(img_path):
    if not os.path.exists(img_path):
        raise FileNotFoundError(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {img_path}")

    print(f"üì∏ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û: {img_path}")

    img = Image.open(img_path).convert("RGB")
    img = transform(img).unsqueeze(0)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô (1, 3, 224, 224)

    with torch.no_grad():
        outputs = model(img)
        _, predicted = outputs.max(1)
    
    predicted_class = CLASS_NAMES[predicted.item()]
    confidence = torch.nn.functional.softmax(outputs, dim=1)[0][predicted.item()].item()

    print(f"‚úÖ ‡∏Ñ‡∏≥‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {predicted_class} (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {confidence:.2f}%)")

# üìå ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
TEST_IMAGE_PATH = "test_image.jpg"  # üîπ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
predict_image(TEST_IMAGE_PATH)
